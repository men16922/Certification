# CKA 2025 KillerCoda ì‹¤ìŠµ ë¬¸ì œì§‘

## ğŸ¯ KillerCoda Playground ì‹¤ìŠµ ê°€ì´ë“œ

**ì‚¬ìš©ë²•:**
1. **KillerCoda Kubernetes Playground** ì ‘ì†: https://killercoda.com/playgrounds/scenario/kubernetes
2. ê° ë¬¸ì œì˜ **í™˜ê²½ ì„¤ì •** ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì œ ìƒí™© ìƒì„±
3. **ë¬¸ì œ**ë¥¼ ì½ê³  í•´ê²° ì‹œë„
4. **ì†”ë£¨ì…˜**ì„ ì°¸ê³ í•˜ì—¬ ê²€ì¦

---

## ğŸ”§ Troubleshooting ë¬¸ì œ

### ë¬¸ì œ 1: Pod ì‹œì‘ ì‹¤íŒ¨ ë¬¸ì œ í•´ê²°

#### ğŸ“‹ ë¬¸ì œ
Namespace `production`ì— ì—¬ëŸ¬ Podë“¤ì´ `ImagePullBackOff`ì™€ `CrashLoopBackOff` ì˜¤ë¥˜ë¡œ ì‹œì‘í•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëª¨ë“  Podë¥¼ ì •ìƒ ìƒíƒœë¡œ ë³µêµ¬í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. ì‹¤íŒ¨í•œ Podë“¤ê³¼ ì˜¤ë¥˜ ì›ì¸ ì‹ë³„
2. ì´ë¯¸ì§€ í’€ ë¬¸ì œ í•´ê²°
3. ì„¤ì • ë¬¸ì œë¡œ ì¸í•œ í¬ë˜ì‹œ í•´ê²°
4. ëª¨ë“  Podê°€ Running ìƒíƒœì¸ì§€ í™•ì¸

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# Namespace ìƒì„±
kubectl create namespace production

# ì˜ëª»ëœ ì´ë¯¸ì§€ ì´ë¦„ì„ ê°€ì§„ Deployment ìƒì„±
kubectl create deployment broken-app1 --image=nginx:wrong-tag -n production

# ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨í•  Deployment ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resource-hungry-app
  namespace: production
spec:
  replicas: 1
  selector:
    matchLabels:
      app: resource-hungry-app
  template:
    metadata:
      labels:
        app: resource-hungry-app
    spec:
      containers:
      - name: app
        image: nginx:1.21
        resources:
          requests:
            cpu: "10"  # ë„ˆë¬´ ë§ì€ CPU ìš”ì²­
            memory: "10Gi"  # ë„ˆë¬´ ë§ì€ ë©”ëª¨ë¦¬ ìš”ì²­
EOF

# ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ConfigMapì„ ì°¸ì¡°í•˜ëŠ” Pod ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: config-dependent-pod
  namespace: production
spec:
  containers:
  - name: app
    image: nginx:1.21
    envFrom:
    - configMapRef:
        name: non-existent-config  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ConfigMap
EOF

# ì˜ëª»ëœ ëª…ë ¹ì–´ë¡œ í¬ë˜ì‹œí•˜ëŠ” Pod ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: crashing-pod
  namespace: production
spec:
  containers:
  - name: app
    image: busybox:1.35
    command: ["invalid-command"]  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ëª…ë ¹ì–´
EOF

echo "ë¬¸ì œ í™˜ê²½ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì•½ 30ì´ˆ í›„ Pod ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. ì‹¤íŒ¨í•œ Pod í™•ì¸
kubectl get pods -n production
kubectl get events -n production --sort-by='.lastTimestamp'

# 2. ê° Podì˜ ìƒì„¸ ì •ë³´ í™•ì¸
kubectl describe pod -n production

# 3. ë¬¸ì œ í•´ê²°

# 3-1. ì˜ëª»ëœ ì´ë¯¸ì§€ íƒœê·¸ ìˆ˜ì •
kubectl set image deployment/broken-app1 broken-app1=nginx:1.21 -n production

# 3-2. ë¦¬ì†ŒìŠ¤ ìš”ì²­ëŸ‰ ìˆ˜ì •
kubectl patch deployment resource-hungry-app -n production -p '{"spec":{"template":{"spec":{"containers":[{"name":"app","resources":{"requests":{"cpu":"100m","memory":"128Mi"}}}]}}}}'

# 3-3. í•„ìš”í•œ ConfigMap ìƒì„±
kubectl create configmap non-existent-config --from-literal=key1=value1 -n production

# 3-4. í¬ë˜ì‹œí•˜ëŠ” Pod ìˆ˜ì •
kubectl delete pod crashing-pod -n production
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: crashing-pod
  namespace: production
spec:
  containers:
  - name: app
    image: busybox:1.35
    command: ["sleep", "3600"]  # ì˜¬ë°”ë¥¸ ëª…ë ¹ì–´
EOF

# 4. ìµœì¢… í™•ì¸
kubectl get pods -n production
kubectl get events -n production --sort-by='.lastTimestamp' | tail -10
```

---

### ë¬¸ì œ 2: ë…¸ë“œ NotReady ë¬¸ì œ í•´ê²°

#### ğŸ“‹ ë¬¸ì œ
í´ëŸ¬ìŠ¤í„°ì˜ ì›Œì»¤ ë…¸ë“œê°€ `NotReady` ìƒíƒœì…ë‹ˆë‹¤. kubelet ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ë…¸ë“œë¥¼ `Ready` ìƒíƒœë¡œ ë³µêµ¬í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. kubelet ì‹¤íŒ¨ ì›ì¸ ì‹ë³„
2. ë¬¸ì œ í•´ê²° ë° ë…¸ë“œë¥¼ Ready ìƒíƒœë¡œ ë³µêµ¬
3. ì¬ë¶€íŒ… í›„ì—ë„ ì§€ì†ë˜ë„ë¡ ì„¤ì •

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# kubelet ì„œë¹„ìŠ¤ ì¤‘ì§€ (ë¬¸ì œ ìƒí™© ì‹œë®¬ë ˆì´ì…˜)
sudo systemctl stop kubelet

# kubelet ì„¤ì • íŒŒì¼ì— ì˜¤ë¥˜ ì¶”ê°€
sudo cp /var/lib/kubelet/config.yaml /var/lib/kubelet/config.yaml.backup
sudo sed -i 's/clusterDNS:/clusterDNS_BROKEN:/' /var/lib/kubelet/config.yaml

echo "kubeletì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì•½ 1ë¶„ í›„ ë…¸ë“œê°€ NotReady ìƒíƒœê°€ ë©ë‹ˆë‹¤."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl get nodes

# 2. ë…¸ë“œ ìƒì„¸ ì •ë³´ í™•ì¸
kubectl describe node $(hostname)

# 3. kubelet ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status kubelet

# 4. kubelet ë¡œê·¸ í™•ì¸
sudo journalctl -u kubelet -f --no-pager | tail -20

# 5. kubelet ì„¤ì • íŒŒì¼ ë³µêµ¬
sudo cp /var/lib/kubelet/config.yaml.backup /var/lib/kubelet/config.yaml

# 6. kubelet ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ë° í™œì„±í™”
sudo systemctl start kubelet
sudo systemctl enable kubelet

# 7. ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl get nodes
kubectl describe node $(hostname) | grep -i ready

# 8. ì‹œìŠ¤í…œ Pod ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system -o wide | grep $(hostname)
```

---

### ë¬¸ì œ 3: ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ í•´ê²°

#### ğŸ“‹ ë¬¸ì œ
`frontend` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ Podë“¤ì´ `backend` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì •ì±…ìœ¼ë¡œ ì¸í•œ ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤. ì—°ê²°ì„ ë³µêµ¬í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°„ ì—°ê²° í…ŒìŠ¤íŠ¸
2. ë„¤íŠ¸ì›Œí¬ ì •ì±… ì œí•œ ì‚¬í•­ ì‹ë³„
3. ì—°ê²° ë¬¸ì œ í•´ê²°
4. ì¢…ë‹¨ ê°„ í†µì‹  ê²€ì¦

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace frontend
kubectl create namespace backend

# Backend ì„œë¹„ìŠ¤ ìƒì„±
kubectl create deployment backend-app --image=nginx:1.21 -n backend
kubectl expose deployment backend-app --name=backend-service --port=80 -n backend

# Frontend Pod ìƒì„±
kubectl run frontend-pod --image=busybox:1.35 -n frontend -- sleep 3600

# ëª¨ë“  íŠ¸ë˜í”½ì„ ì°¨ë‹¨í•˜ëŠ” NetworkPolicy ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
  namespace: backend
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
EOF

# ì˜ëª»ëœ NetworkPolicy ìƒì„± (ì˜ëª»ëœ ë¼ë²¨ ì„ íƒì)
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-wrong
  namespace: backend
spec:
  podSelector:
    matchLabels:
      app: backend-app
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: wrong-frontend  # ì˜ëª»ëœ ë¼ë²¨
    ports:
    - protocol: TCP
      port: 80
EOF

echo "ë„¤íŠ¸ì›Œí¬ ì •ì±…ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. frontendì—ì„œ backendë¡œì˜ ì—°ê²°ì´ ì°¨ë‹¨ë©ë‹ˆë‹¤."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl exec -it frontend-pod -n frontend -- wget -qO- --timeout=5 http://backend-service.backend.svc.cluster.local || echo "Connection failed"

# 2. ë„¤íŠ¸ì›Œí¬ ì •ì±… í™•ì¸
kubectl get networkpolicy -A
kubectl describe networkpolicy -n backend

# 3. ì„œë¹„ìŠ¤ ë° ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
kubectl get svc -n backend
kubectl get endpoints -n backend

# 4. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¼ë²¨ í™•ì¸
kubectl get namespace --show-labels

# 5. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ì˜¬ë°”ë¥¸ ë¼ë²¨ ì¶”ê°€
kubectl label namespace frontend name=frontend

# 6. ì˜¬ë°”ë¥¸ NetworkPolicy ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-correct
  namespace: backend
spec:
  podSelector:
    matchLabels:
      app: backend-app
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: frontend
    ports:
    - protocol: TCP
      port: 80
EOF

# 7. ì˜ëª»ëœ NetworkPolicy ì‚­ì œ
kubectl delete networkpolicy allow-frontend-wrong -n backend

# 8. ì—°ê²° í…ŒìŠ¤íŠ¸ ì¬ì‹œë„
kubectl exec -it frontend-pod -n frontend -- wget -qO- --timeout=5 http://backend-service.backend.svc.cluster.local

# 9. DNS í•´ê²° í…ŒìŠ¤íŠ¸
kubectl exec -it frontend-pod -n frontend -- nslookup backend-service.backend.svc.cluster.local

# 10. ìµœì¢… ê²€ì¦
kubectl get networkpolicy -n backend
kubectl describe networkpolicy allow-frontend-correct -n backend
```

---

## ğŸŒ Services and Networking ë¬¸ì œ

### ë¬¸ì œ 4: ë³µì¡í•œ NetworkPolicy êµ¬í˜„

#### ğŸ“‹ ë¬¸ì œ
3ê³„ì¸µ ì• í”Œë¦¬ì¼€ì´ì…˜ ë³´ì•ˆ ëª¨ë¸ì„ NetworkPolicyë¡œ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- `web-tier`: ì™¸ë¶€ì—ì„œ 80í¬íŠ¸ë¡œë§Œ ì ‘ê·¼ ê°€ëŠ¥
- `app-tier`: `web-tier`ì—ì„œ 8080í¬íŠ¸ë¡œë§Œ ì ‘ê·¼ ê°€ëŠ¥  
- `db-tier`: `app-tier`ì—ì„œ 5432í¬íŠ¸ë¡œë§Œ ì ‘ê·¼ ê°€ëŠ¥
- ë‹¤ë¥¸ ëª¨ë“  í†µì‹ ì€ ì°¨ë‹¨

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ë° ë¼ë²¨ë§
kubectl create namespace web-tier
kubectl create namespace app-tier
kubectl create namespace db-tier

kubectl label namespace web-tier name=web-tier
kubectl label namespace app-tier name=app-tier
kubectl label namespace db-tier name=db-tier

# ê° ê³„ì¸µì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
kubectl create deployment web-app --image=nginx:1.21 -n web-tier
kubectl create deployment app-server --image=nginx:1.21 -n app-tier
kubectl create deployment database --image=postgres:13 -n db-tier --env="POSTGRES_PASSWORD=secret"

# ì„œë¹„ìŠ¤ ìƒì„±
kubectl expose deployment web-app --name=web-service --port=80 -n web-tier
kubectl expose deployment app-server --name=app-service --port=8080 -n app-tier
kubectl expose deployment database --name=db-service --port=5432 -n db-tier

# í…ŒìŠ¤íŠ¸ìš© Pod ìƒì„±
kubectl run test-pod --image=busybox:1.35 -n web-tier -- sleep 3600

echo "3ê³„ì¸µ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ëª¨ë“  í†µì‹ ì´ í—ˆìš©ë©ë‹ˆë‹¤."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. í˜„ì¬ ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸ (ëª¨ë“  ì—°ê²°ì´ ê°€ëŠ¥í•´ì•¼ í•¨)
kubectl exec -it test-pod -n web-tier -- wget -qO- --timeout=5 http://app-service.app-tier.svc.cluster.local:8080 || echo "Connection failed"

# 2. Web-tier NetworkPolicy ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: web-tier-policy
  namespace: web-tier
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - ports:
    - protocol: TCP
      port: 80
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: app-tier
    ports:
    - protocol: TCP
      port: 8080
  - to: []  # DNS í—ˆìš©
    ports:
    - protocol: UDP
      port: 53
EOF

# 3. App-tier NetworkPolicy ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: app-tier-policy
  namespace: app-tier
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: web-tier
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: db-tier
    ports:
    - protocol: TCP
      port: 5432
  - to: []  # DNS í—ˆìš©
    ports:
    - protocol: UDP
      port: 53
EOF

# 4. DB-tier NetworkPolicy ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: db-tier-policy
  namespace: db-tier
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: app-tier
    ports:
    - protocol: TCP
      port: 5432
EOF

# 5. NetworkPolicy í™•ì¸
kubectl get networkpolicy -A

# 6. í—ˆìš©ëœ ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl run test-web -n web-tier --image=busybox:1.35 --rm -it -- wget -qO- --timeout=5 http://app-service.app-tier.svc.cluster.local:8080

# 7. ì°¨ë‹¨ëœ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì‹¤íŒ¨í•´ì•¼ í•¨)
kubectl run test-direct -n web-tier --image=busybox:1.35 --rm -it -- wget -qO- --timeout=5 http://db-service.db-tier.svc.cluster.local:5432 || echo "Connection blocked (expected)"

# 8. ì •ì±… ìƒì„¸ í™•ì¸
kubectl describe networkpolicy -n web-tier
kubectl describe networkpolicy -n app-tier
kubectl describe networkpolicy -n db-tier
```

---

### ë¬¸ì œ 5: Ingressì™€ TLS ì„¤ì •

#### ğŸ“‹ ë¬¸ì œ
ì—¬ëŸ¬ ë„ë©”ì¸ì— ëŒ€í•œ TLS ì¢…ë£Œë¥¼ ì²˜ë¦¬í•˜ëŠ” Ingress ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- `api.example.com` â†’ `api-service:8080`
- `web.example.com` â†’ `web-service:80`
- ë‘ ë„ë©”ì¸ ëª¨ë‘ TLS ì‚¬ìš©
- HTTPë¥¼ HTTPSë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace web-services

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
kubectl create deployment api-app --image=nginx:1.21 -n web-services
kubectl create deployment web-app --image=nginx:1.21 -n web-services

# ì„œë¹„ìŠ¤ ìƒì„±
kubectl expose deployment api-app --name=api-service --port=8080 --target-port=80 -n web-services
kubectl expose deployment web-app --name=web-service --port=80 -n web-services

# NGINX Ingress Controller ì„¤ì¹˜ (KillerCodaì—ì„œëŠ” ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ)
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml

echo "ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë°°í¬ë˜ì—ˆìŠµë‹ˆë‹¤. TLS ì¸ì¦ì„œì™€ Ingressë¥¼ ì„¤ì •í•˜ì„¸ìš”."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. TLS ì¸ì¦ì„œ ìƒì„±
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout api-tls.key -out api-tls.crt \
  -subj "/CN=api.example.com"

openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout web-tls.key -out web-tls.crt \
  -subj "/CN=web.example.com"

# 2. TLS Secret ìƒì„±
kubectl create secret tls api-tls-secret \
  --cert=api-tls.crt --key=api-tls.key -n web-services

kubectl create secret tls web-tls-secret \
  --cert=web-tls.crt --key=web-tls.key -n web-services

# 3. Ingress ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-domain-ingress
  namespace: web-services
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - api.example.com
    secretName: api-tls-secret
  - hosts:
    - web.example.com
    secretName: web-tls-secret
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 8080
  - host: web.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80
EOF

# 4. Ingress ìƒíƒœ í™•ì¸
kubectl get ingress -n web-services
kubectl describe ingress multi-domain-ingress -n web-services

# 5. NGINX Ingress Controller ìƒíƒœ í™•ì¸
kubectl get pods -n ingress-nginx

# 6. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ hosts íŒŒì¼ ì„¤ì • (ì„ íƒì‚¬í•­)
echo "127.0.0.1 api.example.com web.example.com" | sudo tee -a /etc/hosts

# 7. í…ŒìŠ¤íŠ¸ (Ingress Controllerì˜ ì™¸ë¶€ IPê°€ ìˆëŠ” ê²½ìš°)
# curl -k https://api.example.com
# curl -k https://web.example.com

# 8. Secret í™•ì¸
kubectl get secrets -n web-services
kubectl describe secret api-tls-secret -n web-services
```

---

## âš™ï¸ Cluster Architecture ë¬¸ì œ

### ë¬¸ì œ 6: ETCD ë°±ì—… ë° ë³µì›

#### ğŸ“‹ ë¬¸ì œ
ETCD ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°±ì—…ì„ ìƒì„±í•˜ê³ , ìƒˆë¡œìš´ ë°ì´í„° ë””ë ‰í† ë¦¬ë¡œ ë³µì›í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. í˜„ì¬ ETCD ë°ì´í„°ì˜ ì™„ì „í•œ ë°±ì—… ìƒì„±
2. ë°±ì—…ì„ ìƒˆ ë°ì´í„° ë””ë ‰í† ë¦¬ë¡œ ë³µì›
3. í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë° ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
kubectl create namespace backup-test
kubectl create configmap test-data --from-literal=key1=value1 --from-literal=key2=value2 -n backup-test
kubectl create secret generic test-secret --from-literal=username=admin --from-literal=password=secret123 -n backup-test

# í˜„ì¬ ë°ì´í„° í™•ì¸
kubectl get all -n backup-test
kubectl get configmap test-data -n backup-test -o yaml
kubectl get secret test-secret -n backup-test -o yaml

echo "í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ETCD ë°±ì—…ì„ ì§„í–‰í•˜ì„¸ìš”."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. ETCD Pod ë° ì¸ì¦ì„œ ìœ„ì¹˜ í™•ì¸
kubectl get pods -n kube-system | grep etcd
sudo find /etc/kubernetes -name "*.crt" -o -name "*.key" | grep etcd

# 2. ETCD ë°±ì—… ìƒì„±
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot save /opt/etcd-backup-$(date +%Y%m%d-%H%M%S).db

# 3. ë°±ì—… íŒŒì¼ í™•ì¸
ls -la /opt/etcd-backup-*.db

# 4. ë°±ì—… ìƒíƒœ ê²€ì¦
ETCDCTL_API=3 etcdctl snapshot status /opt/etcd-backup-*.db

# 5. ë³µì›ì„ ìœ„í•œ ìƒˆ ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
sudo mkdir -p /var/lib/etcd-restore
sudo chown -R etcd:etcd /var/lib/etcd-restore

# 6. ë°±ì—…ì—ì„œ ë³µì›
ETCDCTL_API=3 etcdctl --data-dir=/var/lib/etcd-restore \
  snapshot restore /opt/etcd-backup-*.db

# 7. etcd.yaml ë°±ì—…
sudo cp /etc/kubernetes/manifests/etcd.yaml /etc/kubernetes/manifests/etcd.yaml.backup

# 8. etcd.yaml ìˆ˜ì • (ë°ì´í„° ë””ë ‰í† ë¦¬ ë³€ê²½)
sudo sed -i 's|/var/lib/etcd|/var/lib/etcd-restore|g' /etc/kubernetes/manifests/etcd.yaml

# 9. etcd Pod ì¬ì‹œì‘ ëŒ€ê¸°
kubectl get pods -n kube-system | grep etcd

# 10. í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
kubectl get nodes
kubectl get pods -A

# 11. ë³µì›ëœ ë°ì´í„° í™•ì¸
kubectl get configmap test-data -n backup-test -o yaml
kubectl get secret test-secret -n backup-test -o yaml

# 12. ETCD í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  endpoint health

echo "ETCD ë°±ì—… ë° ë³µì›ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

### ë¬¸ì œ 7: í´ëŸ¬ìŠ¤í„° ì—…ê·¸ë ˆì´ë“œ

#### ğŸ“‹ ë¬¸ì œ
Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ í˜„ì¬ ë²„ì „ì—ì„œ ë‹¤ìŒ ë§ˆì´ë„ˆ ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. Control Plane ë…¸ë“œ ì—…ê·¸ë ˆì´ë“œ
2. í´ëŸ¬ìŠ¤í„° ê¸°ëŠ¥ ê²€ì¦
3. ëª¨ë“  ì‹œìŠ¤í…œ Podê°€ ì •ìƒ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# í˜„ì¬ í´ëŸ¬ìŠ¤í„° ë²„ì „ í™•ì¸
kubectl version --short
kubectl get nodes

# ì—…ê·¸ë ˆì´ë“œ ì „ ìƒíƒœ í™•ì¸
kubectl get pods -A
kubectl get componentstatuses 2>/dev/null || echo "ComponentStatus API deprecated"

# í…ŒìŠ¤íŠ¸ ì›Œí¬ë¡œë“œ ìƒì„±
kubectl create deployment test-app --image=nginx:1.21 --replicas=2
kubectl expose deployment test-app --port=80 --type=ClusterIP

echo "í´ëŸ¬ìŠ¤í„° ì—…ê·¸ë ˆì´ë“œë¥¼ ì‹œì‘í•˜ì„¸ìš”. í˜„ì¬ ë²„ì „: $(kubectl version --short)"
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. í˜„ì¬ ë²„ì „ í™•ì¸
kubectl version --short
kubeadm version

# 2. ì‚¬ìš© ê°€ëŠ¥í•œ kubeadm ë²„ì „ í™•ì¸
sudo apt update
sudo apt-cache madison kubeadm | head -5

# 3. kubeadm ì—…ê·¸ë ˆì´ë“œ (ì˜ˆ: 1.28.x -> 1.29.x)
# ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì ì ˆí•œ ë²„ì „ì„ ì„ íƒí•˜ì„¸ìš”
UPGRADE_VERSION="1.29.0-1.1"

sudo apt-mark unhold kubeadm && \
sudo apt-get update && sudo apt-get install -y kubeadm=$UPGRADE_VERSION && \
sudo apt-mark hold kubeadm

# 4. kubeadm ë²„ì „ í™•ì¸
kubeadm version

# 5. ì—…ê·¸ë ˆì´ë“œ ê³„íš í™•ì¸
sudo kubeadm upgrade plan

# 6. ì—…ê·¸ë ˆì´ë“œ ì ìš© (ì²« ë²ˆì§¸ control plane ë…¸ë“œì—ì„œ)
sudo kubeadm upgrade apply v1.29.0

# 7. ë…¸ë“œ ë“œë ˆì¸ (ë‹¨ì¼ ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ì—ì„œëŠ” ì£¼ì˜)
kubectl drain $(hostname) --ignore-daemonsets --delete-emptydir-data

# 8. kubeletê³¼ kubectl ì—…ê·¸ë ˆì´ë“œ
sudo apt-mark unhold kubelet kubectl && \
sudo apt-get update && sudo apt-get install -y kubelet=$UPGRADE_VERSION kubectl=$UPGRADE_VERSION && \
sudo apt-mark hold kubelet kubectl

# 9. kubelet ì¬ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl restart kubelet

# 10. ë…¸ë“œ ì–¸ì½”ë“ 
kubectl uncordon $(hostname)

# 11. ì—…ê·¸ë ˆì´ë“œ í™•ì¸
kubectl version --short
kubectl get nodes
kubectl get pods -A

# 12. í…ŒìŠ¤íŠ¸ ì›Œí¬ë¡œë“œ í™•ì¸
kubectl get deployment test-app
kubectl get pods -l app=test-app

# 13. í´ëŸ¬ìŠ¤í„° ìƒíƒœ ìµœì¢… í™•ì¸
kubectl cluster-info
kubectl get events --sort-by='.lastTimestamp' | tail -10

echo "í´ëŸ¬ìŠ¤í„° ì—…ê·¸ë ˆì´ë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ğŸ“¦ Workloads & Scheduling ë¬¸ì œ

### ë¬¸ì œ 8: ê³ ê¸‰ ìŠ¤ì¼€ì¤„ë§ ë° Affinity

#### ğŸ“‹ ë¬¸ì œ
ë³µì¡í•œ Pod ìŠ¤ì¼€ì¤„ë§ ìš”êµ¬ì‚¬í•­ì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ë°ì´í„°ë² ì´ìŠ¤ PodëŠ” SSD ìŠ¤í† ë¦¬ì§€ê°€ ìˆëŠ” ë…¸ë“œì—ë§Œ ìŠ¤ì¼€ì¤„
- ë°ì´í„°ë² ì´ìŠ¤ Podë“¤ì€ ì„œë¡œ ë‹¤ë¥¸ ê°€ìš© ì˜ì—­ì— ë¶„ì‚°
- ì›¹ê³¼ ìºì‹œ PodëŠ” ê°™ì€ ë…¸ë“œì— ë°°ì¹˜
- ìœ ì§€ë³´ìˆ˜ ì¤‘ì¸ ë…¸ë“œì— ëŒ€í•œ ì ì ˆí•œ toleration ì„¤ì •

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace scheduling-test

# ë…¸ë“œ ë¼ë²¨ë§ (ê°€ìƒì˜ ìŠ¤í† ë¦¬ì§€ íƒ€ì…ê³¼ ê°€ìš© ì˜ì—­)
kubectl label node $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') storage-type=ssd
kubectl label node $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') topology.kubernetes.io/zone=zone-a

# ì¶”ê°€ ë…¸ë“œê°€ ìˆë‹¤ë©´ ë‹¤ë¥¸ ë¼ë²¨ ì„¤ì • (KillerCodaëŠ” ë³´í†µ ë‹¨ì¼ ë…¸ë“œ)
# kubectl label node worker-node-02 storage-type=hdd
# kubectl label node worker-node-02 topology.kubernetes.io/zone=zone-b

# ìœ ì§€ë³´ìˆ˜ í…Œì¸íŠ¸ ì„¤ì •
kubectl taint node $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') maintenance=true:NoSchedule

echo "ë…¸ë“œ ë¼ë²¨ë§ê³¼ í…Œì¸íŠ¸ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
kubectl get nodes --show-labels
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl get nodes --show-labels
kubectl describe nodes | grep -i taint

# 2. ë°ì´í„°ë² ì´ìŠ¤ Deployment (Node Affinity + Pod Anti-Affinity + Toleration)
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: database
  namespace: scheduling-test
spec:
  replicas: 2
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: storage-type
                operator: In
                values:
                - ssd
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - database
              topologyKey: topology.kubernetes.io/zone
      tolerations:
      - key: maintenance
        operator: Equal
        value: "true"
        effect: NoSchedule
        tolerationSeconds: 300
      containers:
      - name: database
        image: postgres:13
        env:
        - name: POSTGRES_PASSWORD
          value: "secret"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
EOF

# 3. ìºì‹œ Deployment
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cache
  namespace: scheduling-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cache
  template:
    metadata:
      labels:
        app: cache
    spec:
      tolerations:
      - key: maintenance
        operator: Equal
        value: "true"
        effect: NoSchedule
      containers:
      - name: cache
        image: redis:6-alpine
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
EOF

# 4. ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ Deployment (Pod Affinityë¡œ ìºì‹œì™€ ê°™ì€ ë…¸ë“œì— ë°°ì¹˜)
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: scheduling-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - cache
              topologyKey: kubernetes.io/hostname
      tolerations:
      - key: maintenance
        operator: Equal
        value: "true"
        effect: NoSchedule
      containers:
      - name: web
        image: nginx:1.21
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
EOF

# 5. Pod ë°°ì¹˜ í™•ì¸
kubectl get pods -n scheduling-test -o wide

# 6. Pod ìŠ¤ì¼€ì¤„ë§ ìƒì„¸ ì •ë³´ í™•ì¸
kubectl describe pod -n scheduling-test | grep -A 10 "Node-Selectors\|Tolerations\|Events"

# 7. ë…¸ë“œë³„ Pod ë¶„ì‚° í™•ì¸
kubectl get pods -n scheduling-test -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName,STATUS:.status.phase

# 8. í…Œì¸íŠ¸ ì œê±° í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
kubectl taint node $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') maintenance-

echo "ê³ ê¸‰ ìŠ¤ì¼€ì¤„ë§ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

### ë¬¸ì œ 9: HPAì™€ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

#### ğŸ“‹ ë¬¸ì œ
í¬ê´„ì ì¸ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ êµ¬ì„±í•˜ì„¸ìš”. HPA, ë¦¬ì†ŒìŠ¤ ì¿¼í„°, ë¦¬ë°‹ ë ˆì¸ì§€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

**ìš”êµ¬ì‚¬í•­:**
1. CPUì™€ ë©”ëª¨ë¦¬ ê¸°ë°˜ HPA ì„¤ì •
2. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ ì¿¼í„° êµ¬í˜„
3. ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •
4. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace resource-management

# Metrics Server ì„¤ì¹˜ (HPAë¥¼ ìœ„í•´ í•„ìš”)
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Metrics Serverê°€ KillerCodaì—ì„œ ì‘ë™í•˜ë„ë¡ ì„¤ì • ìˆ˜ì •
kubectl patch deployment metrics-server -n kube-system --type='json' \
  -p='[{"op": "add", "path": "/spec/template/spec/containers/0/args/-", "value": "--kubelet-insecure-tls"}]'

echo "Metrics Serverê°€ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. Metrics Server ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system | grep metrics-server
kubectl top nodes 2>/dev/null || echo "Metrics not ready yet, waiting..."

# 2. Resource Quota ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota
  namespace: resource-management
spec:
  hard:
    requests.cpu: "2"
    requests.memory: 4Gi
    limits.cpu: "4"
    limits.memory: 8Gi
    persistentvolumeclaims: "2"
    pods: "5"
    services: "3"
EOF

# 3. Limit Range ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: LimitRange
metadata:
  name: limit-range
  namespace: resource-management
spec:
  limits:
  - default:
      cpu: 500m
      memory: 512Mi
    defaultRequest:
      cpu: 100m
      memory: 128Mi
    type: Container
  - max:
      cpu: 1
      memory: 1Gi
    min:
      cpu: 50m
      memory: 64Mi
    type: Container
EOF

# 4. ì• í”Œë¦¬ì¼€ì´ì…˜ Deployment ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: resource-management
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: web
        image: nginx:1.21
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        ports:
        - containerPort: 80
EOF

# 5. ì„œë¹„ìŠ¤ ìƒì„±
kubectl expose deployment web-app --name=web-app-service --port=80 -n resource-management

# 6. HPA ìƒì„± (CPUì™€ ë©”ëª¨ë¦¬ ê¸°ë°˜)
cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
  namespace: resource-management
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
EOF

# 7. ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
kubectl get resourcequota -n resource-management
kubectl describe resourcequota resource-quota -n resource-management

kubectl get limitrange -n resource-management
kubectl describe limitrange limit-range -n resource-management

# 8. HPA ìƒíƒœ í™•ì¸
kubectl get hpa -n resource-management
kubectl describe hpa web-app-hpa -n resource-management

# 9. Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸ (ë©”íŠ¸ë¦­ì´ ì¤€ë¹„ë˜ë©´)
sleep 30
kubectl top pods -n resource-management

# 10. ë¶€í•˜ í…ŒìŠ¤íŠ¸ (CPU ì‚¬ìš©ëŸ‰ ì¦ê°€)
kubectl run load-generator --image=busybox:1.35 -n resource-management --rm -it --restart=Never -- \
  sh -c "while true; do wget -q -O- http://web-app-service.resource-management.svc.cluster.local; done" &

# 11. HPA ë™ì‘ ëª¨ë‹ˆí„°ë§
kubectl get hpa -n resource-management -w &
sleep 60
kubectl get pods -n resource-management

# 12. ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì¤‘ì§€
pkill -f "wget.*web-app-service"

echo "ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ğŸ’¾ Storage ë¬¸ì œ

### ë¬¸ì œ 10: ë™ì  ìŠ¤í† ë¦¬ì§€ í”„ë¡œë¹„ì €ë‹

#### ğŸ“‹ ë¬¸ì œ
ë‹¤ì–‘í•œ ì„±ëŠ¥ ê³„ì¸µì˜ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë³¼ë¥¨ í™•ì¥ ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. ë¹ ë¥¸ SSDì™€ í‘œì¤€ HDDìš© ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìƒì„±
2. ë³¼ë¥¨ í™•ì¥ ê¸°ëŠ¥ í™œì„±í™”
3. StatefulSetì—ì„œ ë™ì  ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©
4. ë³¼ë¥¨ í™•ì¥ í…ŒìŠ¤íŠ¸

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace storage-demo

# ê¸°ë³¸ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ í™•ì¸
kubectl get storageclass

echo "ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë™ì  í”„ë¡œë¹„ì €ë‹ì„ ì„¤ì •í•˜ì„¸ìš”."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. í˜„ì¬ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ í™•ì¸
kubectl get storageclass

# 2. Fast SSD Storage Class ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
  annotations:
    storageclass.kubernetes.io/is-default-class: "false"
provisioner: k8s.io/minikube-hostpath  # KillerCoda/Minikubeìš©
parameters:
  type: "fast"
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
EOF

# 3. Standard HDD Storage Class ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard-hdd
provisioner: k8s.io/minikube-hostpath  # KillerCoda/Minikubeìš©
parameters:
  type: "standard"
allowVolumeExpansion: true
volumeBindingMode: Immediate
reclaimPolicy: Retain
EOF

# 4. StatefulSet with ë™ì  ìŠ¤í† ë¦¬ì§€ ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
  namespace: storage-demo
spec:
  serviceName: database
  replicas: 2
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      containers:
      - name: postgres
        image: postgres:13
        env:
        - name: POSTGRES_PASSWORD
          value: "secret"
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 1Gi
EOF

# 5. Headless Service ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: database
  namespace: storage-demo
spec:
  clusterIP: None
  selector:
    app: database
  ports:
  - port: 5432
EOF

# 6. ë³„ë„ PVC ìƒì„± (ë°±ì—…ìš©)
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-pvc
  namespace: storage-demo
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: standard-hdd
  resources:
    requests:
      storage: 2Gi
EOF

# 7. ìŠ¤í† ë¦¬ì§€ ìƒíƒœ í™•ì¸
kubectl get storageclass
kubectl get pv
kubectl get pvc -n storage-demo

# 8. StatefulSet ìƒíƒœ í™•ì¸
kubectl get statefulset -n storage-demo
kubectl get pods -n storage-demo

# 9. ë³¼ë¥¨ í™•ì¥ í…ŒìŠ¤íŠ¸
kubectl patch pvc data-database-0 -n storage-demo -p '{"spec":{"resources":{"requests":{"storage":"2Gi"}}}}'

# 10. í™•ì¥ ìƒíƒœ í™•ì¸
kubectl describe pvc data-database-0 -n storage-demo
kubectl get pvc -n storage-demo

# 11. Pod ë‚´ì—ì„œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
kubectl exec -it database-0 -n storage-demo -- df -h /var/lib/postgresql/data

# 12. ë°ì´í„° ì§€ì†ì„± í…ŒìŠ¤íŠ¸
kubectl exec -it database-0 -n storage-demo -- psql -U postgres -c "CREATE TABLE test_table (id SERIAL PRIMARY KEY, data TEXT);"
kubectl exec -it database-0 -n storage-demo -- psql -U postgres -c "INSERT INTO test_table (data) VALUES ('persistent data');"

# 13. Pod ì¬ì‹œì‘ í›„ ë°ì´í„° í™•ì¸
kubectl delete pod database-0 -n storage-demo
kubectl wait --for=condition=Ready pod/database-0 -n storage-demo --timeout=60s
kubectl exec -it database-0 -n storage-demo -- psql -U postgres -c "SELECT * FROM test_table;"

echo "ë™ì  ìŠ¤í† ë¦¬ì§€ í”„ë¡œë¹„ì €ë‹ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ğŸ” Security ë¬¸ì œ

### ë¬¸ì œ 11: ì¢…í•© ë³´ì•ˆ êµ¬ì„±

#### ğŸ“‹ ë¬¸ì œ
RBAC, Pod Security Standards, ë„¤íŠ¸ì›Œí¬ ì •ì±…ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ ë³´ì•ˆ ì¡°ì¹˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
1. ì‚¬ìš©ì ì •ì˜ RBAC ì—­í•  ë° ë°”ì¸ë”© ìƒì„±
2. Pod Security Standards êµ¬í˜„
3. ìµœì†Œ ê¶Œí•œ ì›ì¹™ìœ¼ë¡œ ì„œë¹„ìŠ¤ ê³„ì • êµ¬ì„±
4. ë³´ì•ˆ ì •ì±… ë° ë„¤íŠ¸ì›Œí¬ ì •ì±… ì„¤ì •

#### ğŸ› ï¸ í™˜ê²½ ì„¤ì • (KillerCodaì—ì„œ ì‹¤í–‰)

```bash
# ë³´ì•ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace secure-apps

# í…ŒìŠ¤íŠ¸ìš© ë¹„ë³´ì•ˆ Pod ìƒì„± (ë‚˜ì¤‘ì— ë³´ì•ˆ ì •ì±…ìœ¼ë¡œ ì°¨ë‹¨ë  ì˜ˆì •)
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-pod
  namespace: secure-apps
spec:
  containers:
  - name: app
    image: nginx:1.21
    securityContext:
      privileged: true  # ë³´ì•ˆ ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë  ì˜ˆì •
EOF

echo "ë³´ì•ˆ í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë³´ì•ˆ ì •ì±…ì„ êµ¬í˜„í•˜ì„¸ìš”."
```

#### âœ… ì†”ë£¨ì…˜

```bash
# 1. ê¸°ì¡´ ë¹„ë³´ì•ˆ Pod ì‚­ì œ
kubectl delete pod insecure-pod -n secure-apps --force --grace-period=0

# 2. Pod Security Standards ì ìš©
kubectl label namespace secure-apps \
  pod-security.kubernetes.io/enforce=restricted \
  pod-security.kubernetes.io/enforce-version=latest \
  pod-security.kubernetes.io/audit=restricted \
  pod-security.kubernetes.io/audit-version=latest \
  pod-security.kubernetes.io/warn=restricted \
  pod-security.kubernetes.io/warn-version=latest

# 3. ì‚¬ìš©ì ì •ì˜ ClusterRole ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-manager
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "create", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "create", "update", "patch"]
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list"]
EOF

# 4. ServiceAccount ìƒì„±
kubectl create serviceaccount pod-manager-sa -n secure-apps

# 5. ClusterRoleBinding ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: pod-manager-binding
subjects:
- kind: ServiceAccount
  name: pod-manager-sa
  namespace: secure-apps
roleRef:
  kind: ClusterRole
  name: pod-manager
  apiGroup: rbac.authorization.k8s.io
EOF

# 6. ë³´ì•ˆ Pod ìƒì„± (Restricted ì •ì±… ì¤€ìˆ˜)
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: secure-app
  namespace: secure-apps
  labels:
    app: secure-app
spec:
  serviceAccountName: pod-manager-sa
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  containers:
  - name: app
    image: nginx:1.21
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-cache
    emptyDir: {}
  - name: var-run
    emptyDir: {}
EOF

# 7. ë„¤íŠ¸ì›Œí¬ ì •ì±… ìƒì„±
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: secure-app-netpol
  namespace: secure-apps
spec:
  podSelector:
    matchLabels:
      app: secure-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: client
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to: []  # DNS í—ˆìš©
    ports:
    - protocol: UDP
      port: 53
  - to:
    - podSelector:
        matchLabels:
          role: database
    ports:
    - protocol: TCP
      port: 5432
EOF

# 8. RBAC í…ŒìŠ¤íŠ¸
kubectl auth can-i create pods --as=system:serviceaccount:secure-apps:pod-manager-sa
kubectl auth can-i delete nodes --as=system:serviceaccount:secure-apps:pod-manager-sa
kubectl auth can-i get pods --as=system:serviceaccount:secure-apps:pod-manager-sa -n secure-apps

# 9. Pod Security Standards í…ŒìŠ¤íŠ¸ (ì‹¤íŒ¨í•´ì•¼ í•¨)
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: insecure-test-pod
  namespace: secure-apps
spec:
  containers:
  - name: app
    image: nginx
    securityContext:
      privileged: true  # ì´ê²ƒì€ ê±°ë¶€ë˜ì–´ì•¼ í•¨
EOF

# 10. ë³´ì•ˆ Pod ìƒíƒœ í™•ì¸
kubectl get pods -n secure-apps
kubectl describe pod secure-app -n secure-apps

# 11. ë„¤íŠ¸ì›Œí¬ ì •ì±… í™•ì¸
kubectl get networkpolicy -n secure-apps
kubectl describe networkpolicy secure-app-netpol -n secure-apps

# 12. ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
kubectl get pod secure-app -n secure-apps -o jsonpath='{.spec.securityContext}' | jq .
kubectl get pod secure-app -n secure-apps -o jsonpath='{.spec.containers[0].securityContext}' | jq .

# 13. ì„œë¹„ìŠ¤ ê³„ì • í† í° í™•ì¸
kubectl describe serviceaccount pod-manager-sa -n secure-apps

echo "ì¢…í•© ë³´ì•ˆ êµ¬ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ğŸ“ KillerCoda ì‹¤ìŠµ ê°€ì´ë“œ

### ğŸ¯ íš¨ê³¼ì ì¸ ì‹¤ìŠµ ë°©ë²•

1. **ìˆœì„œëŒ€ë¡œ ì‹¤ìŠµ**: ë¬¸ì œ 1ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ ì§„í–‰
2. **í™˜ê²½ ì´ˆê¸°í™”**: ê° ë¬¸ì œ ì‹œì‘ ì „ `kubectl delete namespace <namespace>` ë¡œ ì •ë¦¬
3. **ì‹œê°„ ì¸¡ì •**: ì‹¤ì œ ì‹œí—˜ì²˜ëŸ¼ ì‹œê°„ì„ ì¬ë©° ì—°ìŠµ
4. **ë¬¸ì„œ ì°¸ì¡°**: Kubernetes ê³µì‹ ë¬¸ì„œë¥¼ ì ê·¹ í™œìš©

### ğŸ”§ KillerCoda í™˜ê²½ ìµœì í™”

```bash
# kubectl ìë™ì™„ì„± ì„¤ì •
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc

# ìœ ìš©í•œ alias ì„¤ì •
alias k=kubectl
alias kgp='kubectl get pods'
alias kgs='kubectl get svc'
alias kgn='kubectl get nodes'

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export do="--dry-run=client -o yaml"
export now="--force --grace-period 0"
```

### ğŸ“š ì¶”ê°€ í•™ìŠµ ë¦¬ì†ŒìŠ¤

- **KillerCoda Kubernetes Scenarios**: https://killercoda.com/kubernetes
- **Kubernetes ê³µì‹ ë¬¸ì„œ**: https://kubernetes.io/docs/
- **kubectl ì¹˜íŠ¸ì‹œíŠ¸**: https://kubernetes.io/docs/reference/kubectl/cheatsheet/

---

**KillerCodaì—ì„œ ì‹¤ìŠµí•˜ë©° CKA ì‹œí—˜ì„ ì™„ë²½í•˜ê²Œ ì¤€ë¹„í•˜ì„¸ìš”! ğŸš€**

**Good Luck! ğŸ’ª**