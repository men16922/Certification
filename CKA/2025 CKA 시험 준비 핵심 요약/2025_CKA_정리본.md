# 2025 CKA 시험 준비 핵심 요약

## 목차

### 1. 설치 & 환경 구성
- [deb 패키지 설치](#1-deb-패키지-설치)
- [Calico 설치](#2-calico-설치)
- [Flannel 설치](#3-flannel-설치)
- [Helm](#4-helm)
- [Kustomize](#5-kustomize)

### 2. 권한 & 보안
- [PriorityClass](#1-priorityclass)
- [Pod Security Admission(PSA)](#2-pod-security-admission)
- [SecurityContext](#3-securitycontext)
- [Default Mode](#4-default-mode)
- [Taint 종류](#5-taint-종류)
- [Affinity](#6-affinity)
- [PV Node Affinity](#7-pv-node-affinity)

### 3. 워크로드
- [HPA](#1-hpa)
- [SideCar](#2-sidecar)
- [Node 자원 관리](#3-node-자원-관리)
- [kubectl label](#4-kubectl-label)
- [Downward API](#5-downward-api)
- [Pod 문제 해결](#6-pod-문제-해결)

### 4. Service & Network
- [Service - expose](#1-service-expose)
- [NetworkPolicy](#2-networkpolicy)
- [NodePort](#3-nodeport)
- [Headless Service + StatefulSet](#4-headless-service--statefulset)
- [Ingress to Gateway API](#5-ingress-to-gateway-api)
- [HTTPRoute](#6-httproute)
- [Ingress](#7-ingress)

### 5. 스토리지
- [StorageClass](#1-storageclass)
- [PV 복구](#2-pv-복구)
- [Volume, ConfigMap - subPath](#3-volume-configmap-subpath)

### 6. 출력 & 조회
- [explain 결과 조회](#1-explain-결과-조회)
- [JSONPath 사용](#2-jsonpath-사용)

### 7. 트러블슈팅
- [일반적인 문제 해결](#일반적인-문제-해결)

### 8. 기타 팁 & 명령어
- [유용한 명령어](#유용한-명령어)

---

## 1. 설치 & 환경 구성

### 1. deb 패키지 설치

**Question No: 11**

Complete these tasks to prepare the system for Kubernetes:

Set up cri-dockerd:
- Install the Debian package: `~/cri-dockerd_0.3.9.3-0.ubuntu-focal_amd64.deb`
- Start the cri-dockerd service
- Enable and start the systemd service for cri-dockerd

Configure these system parameters:
- Set `net.bridge.bridge-nf-call-iptables` to 1
- Set `net.ipv6.conf.all.forwarding` to 1
- Set `net.ipv4.ip_forward` to 1

**참고 문서:**
- https://kubernetes.io/docs/setup/production-environment/container-runtimes/

```bash
# deb 패키지 설치
dpkg -i ~/cri-dockerd_0.3.9.3-0.ubuntu-focal_amd64.deb

# 서비스 실행 및 활성화
sudo systemctl enable --now cri-docker
sudo systemctl status cri-docker

# 시스템 매개변수 구성
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.ipv6.conf.all.forwarding = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

# 재부팅 없이 적용
sudo sysctl --system

# 확인
sysctl net.ipv4.ip_forward
sysctl net.ipv6.conf.all.forwarding
sysctl net.bridge.bridge-nf-call-iptables
```

### 2. Calico 설치

**조건:** NetworkPolicy 지원이 필요한 경우

The CNI you choose must satisfy following requirement: `<native network policy support>`

Install and configure a Container Network Interface (CNI) that satisfies the following conditions:

- Calico using the manifest: https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml

The chosen CNI must allow:
- Pod-to-Pod communication
- NetworkPolicy enforcement
- Must be installed using manifest files (do not use Helm)

```bash
# Calico 설치 (create 사용!)
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/tigera-operator.yaml

# 테스트
kubectl run test1 --image=busybox --restart=Never -- sleep 3600
kubectl run test2 --image=busybox --restart=Never -- sleep 3600
kubectl exec test1 -- ping -c 4 test2

# Calico pod 생성 확인
kubectl get pods -n kube-system
```

### 3. Flannel 설치

**조건:** 단순 Pod 간 통신만 필요한 경우

```bash
# Flannel 설치
kubectl apply -f https://github.com/flannel-io/flannel/releases/download/v0.26.1/kube-flannel.yml

# 확인
kubectl get pods -n kube-flannel
```

### 4. Helm

#### CRD 관리
- CRD = Custom Resource Definition (사용자 정의 리소스 정의)
- 사이즈가 크기 때문에 CRD가 있는 파일은 `kubectl create -f`로 설치

#### Helm Template
Helm chart를 실제로 Kubernetes에 설치하지 않고, 생성될 리소스들을 YAML 형태로 출력

```bash
# Template 생성
helm template argocd argo/argo-cd --version 7.7.3 -n argocd \
  --set crds.install=false > ~/argo-helm.yaml

# Values 확인
helm show values argo/argo-cd --version 7.7.3

# 기존 release values 조회
helm get values kocoon-hermes -n logging
```

#### Helm Install
```bash
# Repository 추가
helm repo add argo https://argoproj.github.io/argo-helm

# CRD 이미 존재하는 경우
helm install argocd argo/argo-cd --version 7.7.3 --skip-crds
# 또는
helm install argocd argo/argo-cd --version 7.7.3 --set crds.install=false
```

#### Helm Pull
```bash
# Chart 다운로드 및 압축 해제
helm pull argo/argo-cd --version 7.7.3 --untar --untardir ./charts
```

### 5. Kustomize

```bash
# 디렉토리 구조
my-kustomize/
├── base/
│   ├── deployment.yaml
│   ├── service.yaml
│   └── kustomization.yaml
└── overlays/
    └── prod/
        ├── kustomization.yaml
        └── deployment-patch.yaml
```

```yaml
# overlays/prod/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ../../base

namespace: prod
namePrefix: prod-

commonLabels:
  env: prod

patchesStrategicMerge:
  - deployment-patch.yaml
```

```bash
# 리소스 생성
kubectl apply -k overlays/prod

# 결과 확인 (적용하지 않고)
kubectl kustomize overlays/prod

# YAML 파일로 저장
kubectl kustomize overlays/prod > /root/final.yaml
```

---

## 2. 권한 & 보안

### 1. PriorityClass

리소스가 부족할 때 "누굴 먼저 죽이고 누굴 살릴지" 결정하는 기준

**문제 예시:**
Create a new PriorityClass named `high-priority` for user workloads with a value that is one less than the highest existing user-defined priority class value.

```bash
# PriorityClass 생성
kubectl create priorityclass high-priority --value=999

# Deployment에 적용
kubectl patch deployment busybox-logger -n priority \
  -p '{"spec":{"template":{"spec":{"priorityClassName":"high-priority"}}}}'

# 강제 재시작 (필요시)
kubectl rollout restart deployment busybox-logger -n priority
```

```yaml
# Deployment에서 설정
spec:
  template:
    spec:
      priorityClassName: high-priority
      preemptionPolicy: PreemptLowerPriority  # 기본값
```

**PreemptionPolicy 옵션:**
- `PreemptLowerPriority` (기본값): 자신보다 우선순위가 낮은 pod를 쫓아낼 수 있음
- `Never`: 절대로 다른 pod를 쫓아내지 않음

### 2. Pod Security Admission(PSA)

PodSecurityPolicy (PSP)는 Kubernetes 1.25에서 완전히 제거됨
PSA는 Pod 자체가 아닌 Namespace에 레이블을 붙여서 해당 네임스페이스 내 모든 Pod을 제어

**레이블 종류:**
- `pod-security.kubernetes.io/enforce`: 적용할 모드
- `pod-security.kubernetes.io/enforce-version`: 보안 정책 버전
- `pod-security.kubernetes.io/warn`: 경고만 표시
- `pod-security.kubernetes.io/audit`: 로그에만 기록

**보안 모드:**
- `privileged`: 제한 거의 없음
- `baseline`: 최소한의 제약
- `restricted`: 가장 보안 수준이 높은 모드

```bash
# 네임스페이스 생성 및 정책 적용
kubectl create ns secure-ns
kubectl label ns secure-ns \
  pod-security.kubernetes.io/enforce=restricted \
  pod-security.kubernetes.io/enforce-version=latest

# 네임스페이스 라벨 확인
kubectl get ns --show-labels
```

### 3. SecurityContext

컨테이너 또는 Pod 수준에서 보안 관련 설정을 지정

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  securityContext:         # Pod 수준
    runAsNonRoot: true
    fsGroup: 2000         # 볼륨 접근 시 group 권한

  containers:
  - name: nginx
    image: nginx
    securityContext:       # 컨테이너 수준
      privileged: false
      allowPrivilegeEscalation: false
      runAsUser: 1000
      capabilities:
        add: ["SYS_TIME"]
        drop: ["ALL"]
      readOnlyRootFilesystem: true
```

**Restricted 모드에서 필수 설정:**
- `runAsNonRoot: true` ✅ 필수
- `allowPrivilegeEscalation: false` ✅ 필수
- `capabilities.drop: ["ALL"]` ✅ 권장
- `privileged: false` ✅ 필수

### 4. Default Mode

ConfigMap, Secret 등을 Pod 안에 파일로 마운트할 때 파일 권한 설정

```yaml
volumes:
- name: config-vol
  configMap:
    name: my-config
    defaultMode: 0400   # 파일 퍼미션 설정
```

**주의사항:**
- 파일에만 적용됨 (디렉토리는 0755로 고정)
- configMap, secret, downwardAPI 볼륨에만 적용
- 일반 볼륨(emptyDir, hostPath, PVC)에는 적용 안됨

### 5. Taint 종류

노드에 조건을 걸어서 특정 Pod만 올라올 수 있게 막는 기능

**Taint 효과:**
- `NoSchedule`: Pod이 스케줄되지 않음
- `NoExecute`: 기존 Pod도 즉시 eviction
- `PreferNoSchedule`: 가능하면 스케줄하지 않음

```bash
# Taint 확인
kubectl describe node node1 | grep Taint

# Toleration 설정
```

```yaml
spec:
  tolerations:
  - key: "node-role.kubernetes.io/master"
    operator: "Exists"
    effect: "NoSchedule"
  
  # NoExecute의 경우
  - key: "zone"
    operator: "Equal"
    value: "test"
    effect: "NoExecute"
    tolerationSeconds: 60  # 60초 후 eviction
```

### 6. Affinity

#### Node Affinity
특정 노드에 파드 배치 유도

```yaml
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disktype
            operator: In
            values:
            - ssd
      
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: availability-zone
            operator: In
            values:
            - zone1
```

#### Pod Affinity/Anti-Affinity

```yaml
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values:
            - S1
        topologyKey: topology.kubernetes.io/zone
    
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: security
              operator: In
              values:
              - S2
          topologyKey: topology.kubernetes.io/zone
```

**TopologyKey 값:**
- `topology.kubernetes.io/zone`: 같은 zone
- `kubernetes.io/hostname`: 같은 노드

### 7. PV Node Affinity

PV에 node affinity가 있으면, 해당 PV를 사용하는 Pod도 해당 노드에 떠야 함

```yaml
# PV에서의 nodeAffinity
spec:
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: disktype
          operator: In
          values:
          - ssd

# Pod에서 특정 노드 지정
spec:
  nodeSelector:
    kubernetes.io/hostname: node02
```

---

## 3. 워크로드

### 1. HPA

**문제 예시:**
Create a new HorizontalPodAutoscaler (HPA) named `apache-server` in the `autoscale` namespace targeting 50% CPU usage.

```bash
# HPA 생성 (명령형)
kubectl autoscale deployment apache-server -n autoscale --min=1 --max=4 --cpu-percent=50

# HPA 편집 (behavior 추가)
kubectl edit hpa apache-server -n autoscale
```

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: apache-server
  namespace: autoscale
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: apache-server
  minReplicas: 1
  maxReplicas: 4
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 30
```

### 2. SideCar

**문제 예시:**
Update the existing deployment `synergy-leverager`, adding a co-located container named `sidecar` using the `busybox:stable` image.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: synergy-leverager
spec:
  template:
    spec:
      containers:
      - name: app
        image: nginx:latest
        volumeMounts:
        - name: log-volume
          mountPath: /var/log
      
      - name: sidecar
        image: busybox:stable
        command: ["/bin/sh", "-c", "tail -n+1 -f /var/log/synergy-leverager.log"]
        volumeMounts:
        - name: log-volume
          mountPath: /var/log
      
      volumes:
      - name: log-volume
        emptyDir: {}
```

**Multi-Container Pod 예시:**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mc-pod
  namespace: mc-namespace
spec:
  containers:
  - name: mc-pod-1
    image: nginx:1-alpine
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  
  - name: mc-pod-2
    image: busybox:1
    command:
    - sh
    - -c
    - "while true; do date >> /var/log/shared/date.log; sleep 1; done"
    volumeMounts:
    - mountPath: /var/log/shared
      name: cache-volume
  
  - name: mc-pod-3
    image: busybox:1
    command:
    - sh
    - -c
    - "tail -f /var/log/shared/date.log"
    volumeMounts:
    - mountPath: /var/log/shared
      name: cache-volume
  
  volumes:
  - name: cache-volume
    emptyDir: {}
```

### 3. Node 자원 관리

**문제:** WordPress 애플리케이션의 Pod 리소스를 노드 자원의 1/3로 균등 분배

```bash
# 노드 자원 확인
kubectl describe node | grep -i allocatable -A5

# 리소스 요청 설정 (3등분)
resources:
  requests:
    memory: "2Gi"
    cpu: "1"
```

### 4. kubectl label

```bash
# 라벨 추가
kubectl label pod my-pod app=web

# 라벨 수정
kubectl label pod my-pod app=backend --overwrite

# 라벨 삭제
kubectl label pod my-pod app-
```

### 5. Downward API

클러스터 정보를 Pod 안으로 전달하는 방식

```yaml
# 환경 변수로 전달
env:
- name: MY_POD_NAME
  valueFrom:
    fieldRef:
      fieldPath: metadata.name

- name: CPU_REQUEST
  valueFrom:
    resourceFieldRef:
      resource: requests.cpu
      divisor: 1Mi

# 볼륨 파일로 전달
volumeMounts:
- name: podinfo
  mountPath: /etc/podinfo
  readOnly: true

volumes:
- name: podinfo
  downwardAPI:
    items:
    - path: "pod_name"
      fieldRef:
        fieldPath: metadata.name
```

### 6. Pod 문제 해결

**일반적인 문제:**
- `0/3 nodes are available: 1 Insufficient cpu, 2 Insufficient memory`

**해결 방법:**
1. 노드 리소스 확인: `kubectl describe nodes | grep -i allocatable -A5`
2. Pod requests 값 줄이기
3. 특정 노드에 강제 배치

```yaml
# nodeName 사용 (스케줄러 건너뛰기)
spec:
  nodeName: node01

# nodeSelector 사용 (스케줄러 활용)
spec:
  nodeSelector:
    kubernetes.io/hostname: node01
```

---

## 4. Service & Network

### 1. Service - expose

```bash
# ClusterIP 서비스 생성
kubectl expose pod messaging --port=6379 --name=messaging-service

# NodePort 서비스 생성
kubectl expose deployment front-end --name=front-end-svc --port=80 --type=NodePort
```

**참고:** `kubectl expose` 명령어는 Pod의 containerPort를 자동으로 targetPort로 사용

### 2. NetworkPolicy

**모든 ingress 요청 허용:**

```yaml
spec:
  ingress:
  - ports:
    - protocol: TCP
      port: 80
```

**복합 NetworkPolicy 예시:**

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: app-security
  namespace: secure-app
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.16.0.0/16
        except:
        - 172.16.1.0/24
    - namespaceSelector:
        matchLabels:
          env: trusted
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5432
```

### 3. NodePort

```yaml
apiVersion: v1
kind: Service
metadata:
  name: front-end-svc
spec:
  type: NodePort
  selector:
    app: front-end
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30080
```

### 4. Headless Service + StatefulSet

고정된 DNS는 Headless Service가 있어야 가능

```yaml
# StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  serviceName: web  # 중요!
  replicas: 2

---
# Headless Service
apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  clusterIP: None  # 핵심!
  selector:
    app: web
```

**결과:** `web-0.web.default.svc.cluster.local`, `web-1.web.default.svc.cluster.local`

### 5. Ingress to Gateway API

**기존 Ingress:**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web
spec:
  tls:
  - hosts:
    - gateway.web.k8s.local
    secretName: web-tls
  rules:
  - host: gateway.web.k8s.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80
```

**Gateway로 변환:**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: web-gateway
spec:
  gatewayClassName: nginx
  listeners:
  - name: https
    protocol: HTTPS
    port: 443
    hostname: gateway.web.k8s.local
    tls:
      certificateRefs:
      - kind: Secret
        name: web-tls
```

### 6. HTTPRoute

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: web-route
spec:
  parentRefs:
  - name: web-gateway
  hostnames:
  - "gateway.web.k8s.local"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: web-service
      port: 80
```

### 7. Ingress

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kodekloud-ingress
spec:
  ingressClassName: nginx
  rules:
  - host: kodekloud-ingress.app
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: webapp-svc
            port:
              number: 80
```

---

## 5. 스토리지

### 1. StorageClass

**문제 예시:**
Create a new StorageClass named `local-path` for an existing provisioner named `rancher.io/local-path`. Set as default.

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-path
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: rancher.io/local-path
volumeBindingMode: WaitForFirstConsumer
```

**기본 StorageClass 설정:**
1. 기존 기본 StorageClass에서 annotation 제거
2. 새 StorageClass에 `storageclass.kubernetes.io/is-default-class: "true"` 추가

### 2. PV 복구

**문제 예시:**
A MariaDB Deployment was deleted. Restore it using existing retained PV.

```yaml
# PVC 생성
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mariadb
  namespace: mariadb
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 250Mi
  storageClassName: standard

---
# Deployment 복구
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mariadb
  namespace: mariadb
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mariadb
  template:
    metadata:
      labels:
        app: mariadb
    spec:
      containers:
      - name: mariadb
        image: mariadb:latest
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: "password"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: mariadb
```

### 3. Volume, ConfigMap - subPath

subPath를 사용하면 ConfigMap 중에서 특정 key만 파일로 저장 가능

```yaml
volumeMounts:
- name: config-volume
  mountPath: /etc/nginx/nginx.conf
  subPath: nginx.conf

volumes:
- name: config-volume
  configMap:
    name: nginx-config
```

---

## 6. 출력 & 조회

### 1. explain 결과 조회

```bash
# 리소스 스펙 확인
kubectl explain pod.spec.containers.resources

# 특정 필드 설명
kubectl explain deployment.spec.strategy
```

### 2. JSONPath 사용

```bash
# 노드 OS 정보 추출
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.nodeInfo.osImage}{"\n"}{end}' > /tmp/node-os-info.txt

# Pod IP 추출
kubectl get pods -o jsonpath='{.items[*].status.podIP}'

# 특정 필드 정렬
kubectl get pods --sort-by='.metadata.creationTimestamp'
kubectl get pods --sort-by='.metadata.uid'
```

---

## 7. 트러블슈팅

### 일반적인 문제 해결

**Pod이 Pending 상태:**
```bash
kubectl describe pod <pod-name>
kubectl get events --sort-by='.lastTimestamp'
```

**일반적인 원인:**
- 리소스 부족 (CPU/Memory)
- Node Taint
- PVC 바인딩 실패
- Image Pull 실패

**Node가 NotReady:**
```bash
kubectl describe node <node-name>

# Node에 SSH 접속 후
sudo systemctl status kubelet
sudo systemctl status containerd
sudo journalctl -u kubelet -f

# 서비스 재시작
sudo systemctl restart kubelet
sudo systemctl enable kubelet
```

---

## 8. 기타 팁 & 명령어

### 유용한 명령어

```bash
# kubectl 단축키
alias k=kubectl
export do="--dry-run=client -o yaml"
export now="--force --grace-period 0"

# 자주 사용하는 명령어
k get po -A
k describe po <pod-name>
k logs <pod-name> -f
k edit <resource> <name>
k delete po <pod-name> $now

# 리소스 생성 템플릿
k run nginx --image=nginx $do > nginx.yaml
k create deploy web --image=nginx $do > web.yaml
k expose pod nginx --port=80 $do > svc.yaml
```

### Vim 설정

```bash
# ~/.vimrc
set expandtab
set tabstop=2
set shiftwidth=2
set number
```

### 시험 팁

1. **시간 관리:** 총 2시간, 문제당 평균 5-8분
2. **어려운 문제는 나중에:** 쉬운 문제부터 해결
3. **공식 문서 활용:** https://kubernetes.io/docs/
4. **명령어 우선:** 가능하면 kubectl 명령어 사용
5. **검증 필수:** 생성 후 반드시 동작 확인

### 자주 사용하는 참고 문서

- **일반:** https://kubernetes.io/docs/reference/kubectl/cheatsheet/
- **네트워킹:** https://kubernetes.io/docs/concepts/services-networking/
- **스토리지:** https://kubernetes.io/docs/concepts/storage/
- **보안:** https://kubernetes.io/docs/concepts/security/
- **스케줄링:** https://kubernetes.io/docs/concepts/scheduling-eviction/

---

**Good Luck with your CKA Exam! 🚀**